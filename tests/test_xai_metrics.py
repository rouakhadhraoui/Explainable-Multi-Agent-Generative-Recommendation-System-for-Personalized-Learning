# tests/test_xai_metrics.py
"""
Tests pour les m√©triques XAI (Explicabilit√©)

V√©rifie que les m√©triques d'explicabilit√© sont correctement impl√©ment√©es
"""

import sys
sys.path.append('..')

from evaluation.xai_metrics import XAIMetrics, print_xai_metrics_report


def test_faithfulness():
    """Test de la fid√©lit√©"""
    print("\n" + "="*70)
    print("TEST 1 : Faithfulness (Fid√©lit√©)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Cas 1 : Explication fid√®le (mentionne les features importantes)
    explanation = {
        "level_reasoning": "The level beginner was assigned based on low quiz scores",
        "style_reasoning": "Visual learning style detected from video preferences"
    }
    
    actual_features = {
        "level": "beginner",
        "learning_style": "visual",
        "avg_score": 55
    }
    
    feature_importance = {
        "level": 0.35,
        "learning_style": 0.25,
        "avg_score": 0.20,
        "total_interactions": 0.10
    }
    
    faithfulness = metrics.faithfulness_score(explanation, actual_features, feature_importance)
    
    print(f"\nüìä Cas 1 : Explication fid√®le")
    print(f"  Features importantes mentionn√©es")
    print(f"  Faithfulness : {faithfulness:.4f}")
    
    assert faithfulness > 0.5, "‚ùå Faithfulness devrait √™tre > 0.5"
    
    # Cas 2 : Explication non fid√®le
    explanation2 = {
        "reasoning": "The user likes Python"
    }
    
    faithfulness2 = metrics.faithfulness_score(explanation2, actual_features, feature_importance)
    
    print(f"\nüìä Cas 2 : Explication non fid√®le")
    print(f"  Features importantes non mentionn√©es")
    print(f"  Faithfulness : {faithfulness2:.4f}")
    
    assert faithfulness2 < faithfulness, "‚ùå Faithfulness devrait √™tre plus basse"
    
    print("\n‚úÖ TEST 1 R√âUSSI - Faithfulness correctement impl√©ment√©")


def test_plausibility():
    """Test de la plausibilit√©"""
    print("\n" + "="*70)
    print("TEST 2 : Plausibility (Plausibilit√©)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Cas 1 : Explication plausible
    explanation1 = {
        "level_reasoning": "The beginner level was assigned because the average quiz score is 55%, which is below the intermediate threshold of 60%.",
        "style_reasoning": "Visual learning style was detected since the user primarily watched 5 video tutorials."
    }
    
    plausibility1 = metrics.plausibility_score(explanation1)
    
    print(f"\nüìä Cas 1 : Explication plausible et structur√©e")
    print(f"  Plausibility : {plausibility1:.4f}")
    
    # Cas 2 : Explication peu plausible
    explanation2 = "User is beginner"
    
    plausibility2 = metrics.plausibility_score(explanation2)
    
    print(f"\nüìä Cas 2 : Explication courte et vague")
    print(f"  Plausibility : {plausibility2:.4f}")
    
    assert plausibility1 > plausibility2, "‚ùå Explication 1 devrait √™tre plus plausible"
    
    print("\n‚úÖ TEST 2 R√âUSSI - Plausibility correctement impl√©ment√©")


def test_completeness():
    """Test de la compl√©tude"""
    print("\n" + "="*70)
    print("TEST 3 : Completeness (Compl√©tude)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Cas 1 : Explication compl√®te
    explanation1 = {
        "level_reasoning": "Beginner level based on scores",
        "style_reasoning": "Visual style based on videos",
        "interests_reasoning": "Python interest from interactions"
    }
    
    required = ['level_reasoning', 'style_reasoning', 'interests_reasoning']
    
    completeness1 = metrics.completeness_score(explanation1, required)
    
    print(f"\nüìä Cas 1 : Explication compl√®te (3/3 composants)")
    print(f"  Completeness : {completeness1:.4f}")
    
    assert completeness1 == 1.0, "‚ùå Completeness devrait √™tre 1.0"
    
    # Cas 2 : Explication incompl√®te
    explanation2 = {
        "level_reasoning": "Beginner level based on scores"
    }
    
    completeness2 = metrics.completeness_score(explanation2, required)
    
    print(f"\nüìä Cas 2 : Explication incompl√®te (1/3 composants)")
    print(f"  Completeness : {completeness2:.4f}")
    
    assert completeness2 < 1.0, "‚ùå Completeness devrait √™tre < 1.0"
    
    print("\n‚úÖ TEST 3 R√âUSSI - Completeness correctement impl√©ment√©")


def test_trust_score():
    """Test du score de confiance"""
    print("\n" + "="*70)
    print("TEST 4 : Trust Score (Confiance)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Explication avec donn√©es concr√®tes
    explanation = {
        "level_reasoning": "Beginner level assigned based on average score of 55% across 10 interactions",
        "style_reasoning": "Visual learning style detected from 8 video views and 2 exercises"
    }
    
    confidence_indicators = {
        "data_quality": 0.9,
        "model_confidence": 0.85
    }
    
    trust = metrics.trust_score_heuristic(explanation, confidence_indicators)
    
    print(f"\nüìä Score de confiance")
    print(f"  Trust Score : {trust:.4f}")
    
    assert 0 <= trust <= 1, "‚ùå Trust score devrait √™tre entre 0 et 1"
    
    print("\n‚úÖ TEST 4 R√âUSSI - Trust Score correctement impl√©ment√©")


def test_consistency():
    """Test de la coh√©rence"""
    print("\n" + "="*70)
    print("TEST 5 : Consistency (Coh√©rence)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Explications coh√©rentes (m√™mes th√®mes)
    explanations1 = [
        {"reasoning": "Beginner level based on low scores"},
        {"reasoning": "Beginner level due to low performance"},
        {"reasoning": "Beginner assigned from poor scores"}
    ]
    
    consistency1 = metrics.consistency_score(explanations1)
    
    print(f"\nüìä Cas 1 : Explications coh√©rentes")
    print(f"  Consistency : {consistency1:.4f}")
    
    # Explications incoh√©rentes
    explanations2 = [
        {"reasoning": "Beginner level based on scores"},
        {"reasoning": "Visual style from videos"},
        {"reasoning": "Python interest detected"}
    ]
    
    consistency2 = metrics.consistency_score(explanations2)
    
    print(f"\nüìä Cas 2 : Explications moins coh√©rentes")
    print(f"  Consistency : {consistency2:.4f}")
    
    assert consistency1 > consistency2, "‚ùå Cas 1 devrait √™tre plus coh√©rent"
    
    print("\n‚úÖ TEST 5 R√âUSSI - Consistency correctement impl√©ment√©")


def test_contrastive_quality():
    """Test de la qualit√© des contrefactuels"""
    print("\n" + "="*70)
    print("TEST 6 : Contrastive Quality (Qualit√© des contrefactuels)")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Bons contrefactuels
    counterfactuals1 = {
        "if_higher_level": "If your level was intermediate, you would receive more advanced resources",
        "if_different_style": "If you had a kinesthetic style, more exercises would be recommended",
        "if_more_practice": "If you completed 10 more interactions, your level could improve"
    }
    
    quality1 = metrics.contrastive_quality_score(counterfactuals1)
    
    print(f"\nüìä Cas 1 : Contrefactuels d√©taill√©s")
    print(f"  Contrastive Quality : {quality1:.4f}")
    
    # Contrefactuels vagues
    counterfactuals2 = {
        "scenario": "Things would be different"
    }
    
    quality2 = metrics.contrastive_quality_score(counterfactuals2)
    
    print(f"\nüìä Cas 2 : Contrefactuels vagues")
    print(f"  Contrastive Quality : {quality2:.4f}")
    
    assert quality1 > quality2, "‚ùå Cas 1 devrait avoir meilleure qualit√©"
    
    print("\n‚úÖ TEST 6 R√âUSSI - Contrastive Quality correctement impl√©ment√©")


def test_evaluate_all():
    """Test de l'√©valuation compl√®te"""
    print("\n" + "="*70)
    print("TEST 7 : √âvaluation XAI Compl√®te")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # Explication compl√®te
    explanation = {
        "profile_explanation": {
            "level_reasoning": "Beginner level due to average score of 58%",
            "style_reasoning": "Visual style from 10 video views",
            "interests_reasoning": "Python interest from interactions"
        },
        "path_explanation": {
            "path_logic": "Path starts with basics",
            "personalization": "Adapted to visual style",
            "expected_outcomes": "Master fundamentals"
        },
        "recommendations_explanation": {
            "selection_criteria": "Based on level and style",
            "ranking_logic": "Priority to foundational topics",
            "personalization_factors": "Visual resources prioritized"
        },
        "counterfactuals": {
            "if_higher_level": "More advanced content",
            "if_different_style": "Different resource types"
        }
    }
    
    actual_features = {
        "level": "beginner",
        "learning_style": "visual"
    }
    
    feature_importance = {
        "level": 0.35,
        "learning_style": 0.25
    }
    
    results = metrics.evaluate_all(explanation, actual_features, feature_importance)
    
    print_xai_metrics_report(results, title="R√©sultats d'√âvaluation XAI")
    
    # V√©rifications
    assert 'plausibility' in results, "‚ùå Plausibility manquante"
    assert 'profile_completeness' in results, "‚ùå Profile completeness manquante"
    assert 'trust_score' in results, "‚ùå Trust score manquant"
    
    print("‚úÖ TEST 7 R√âUSSI - √âvaluation XAI compl√®te fonctionnelle")


def test_batch_evaluation():
    """Test de l'√©valuation en batch"""
    print("\n" + "="*70)
    print("TEST 8 : √âvaluation XAI en BATCH")
    print("="*70)
    
    metrics = XAIMetrics()
    
    # 3 explications
    batch = [
        {"profile_explanation": {"level_reasoning": "Beginner due to scores", "style_reasoning": "Visual from videos"}},
        {"profile_explanation": {"level_reasoning": "Intermediate from performance", "style_reasoning": "Kinesthetic from exercises"}},
        {"profile_explanation": {"level_reasoning": "Advanced based on results", "style_reasoning": "Reading from articles"}}
    ]
    
    avg_results = metrics.evaluate_batch(batch)
    
    print_xai_metrics_report(avg_results, title="R√©sultats Moyens XAI (3 explications)")
    
    # V√©rifications
    assert 'plausibility_std' in avg_results, "‚ùå √âcart-type manquant"
    assert 'consistency' in avg_results, "‚ùå Consistency manquante"
    
    print("‚úÖ TEST 8 R√âUSSI - √âvaluation batch XAI fonctionnelle")


def run_all_tests():
    """Ex√©cuter tous les tests"""
    print("\n" + "#"*70)
    print("# SUITE DE TESTS - M√âTRIQUES XAI")
    print("#"*70)
    
    try:
        test_faithfulness()
        test_plausibility()
        test_completeness()
        test_trust_score()
        test_consistency()
        test_contrastive_quality()
        test_evaluate_all()
        test_batch_evaluation()
        
        print("\n" + "="*70)
        print("üéâ TOUS LES TESTS DES M√âTRIQUES XAI R√âUSSIS !")
        print("="*70)
        print("\n‚úÖ Toutes les m√©triques d'explicabilit√© impl√©ment√©es")
        print("‚úÖ Faithfulness, Plausibility, Trust Score valid√©s")
        print("\nüéØ √âTAPE 10 COMPL√àTE - Toutes les m√©triques d'√©valuation sont pr√™tes !\n")
        
    except AssertionError as e:
        print(f"\n‚ùå √âCHEC DU TEST: {e}")
    except Exception as e:
        print(f"\n‚ùå ERREUR INATTENDUE: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_all_tests()