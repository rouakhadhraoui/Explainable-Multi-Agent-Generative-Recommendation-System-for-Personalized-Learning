# tests/test_orchestrator.py
"""
Tests pour l'Orchestrator

Ce fichier teste la coordination des agents et le flux du pipeline
"""

import sys
sys.path.append('..')

from memory.blackboard import Blackboard
from orchestrator.orchestrator import Orchestrator, AgentStatus


def setup_test_user(blackboard: Blackboard, user_id: str):
    """
    CrÃ©e des donnÃ©es de test pour un utilisateur
    
    Args:
        blackboard: Instance du Blackboard
        user_id: ID de l'utilisateur
    """
    # Ajouter un historique d'interactions
    interactions = [
        {"type": "view", "resource_id": "video_python_intro", "duration": 180},
        {"type": "quiz", "resource_id": "quiz_python_basics", "score": 75},
        {"type": "view", "resource_id": "course_python_loops", "duration": 240},
        {"type": "quiz", "resource_id": "quiz_python_loops", "score": 82},
        {"type": "exercise", "resource_id": "exercise_python_functions", "duration": 600},
        {"type": "quiz", "resource_id": "quiz_python_functions", "score": 88},
    ]
    
    for interaction in interactions:
        blackboard.add_to_history(user_id, interaction)
    
    print(f"âœ“ {len(interactions)} interactions crÃ©Ã©es pour {user_id}")


def test_orchestrator_initialization():
    """Test d'initialisation de l'orchestrateur"""
    print("\n" + "="*80)
    print("TEST 1 : Initialisation de l'Orchestrator")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # VÃ©rifier que l'orchestrateur est bien initialisÃ©
    assert len(orchestrator.agents) > 0, "âŒ Aucun agent initialisÃ©"
    assert "profiling" in orchestrator.agents, "âŒ Agent profiling manquant"
    
    # VÃ©rifier le pipeline
    assert len(orchestrator.pipeline) > 0, "âŒ Pipeline vide"
    
    # Afficher les infos
    info = orchestrator.get_pipeline_info()
    print(f"\nğŸ“Š Informations du pipeline:")
    print(f"  - Agents disponibles: {info['agents_available']}")
    print(f"  - Ã‰tapes du pipeline: {info['pipeline']}")
    print(f"  - Statut des agents: {info['agents_status']}")
    
    print(f"\n{orchestrator}")
    
    print("\nâœ… TEST 1 RÃ‰USSI - Orchestrator initialisÃ© correctement")


def test_profile_only_request():
    """Test d'une requÃªte profile_only"""
    print("\n" + "="*80)
    print("TEST 2 : RequÃªte 'profile_only'")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # CrÃ©er un utilisateur de test
    user_id = "test_user_001"
    setup_test_user(bb, user_id)
    
    # ExÃ©cuter une requÃªte profile_only
    result = orchestrator.process_user_request(user_id, request_type="profile_only")
    
    # VÃ©rifications
    assert result["overall_status"] == "completed", "âŒ La requÃªte devrait Ãªtre complÃ©tÃ©e"
    assert "profiling" in result["agents_results"], "âŒ RÃ©sultat du profiling manquant"
    assert result["agents_results"]["profiling"]["status"] == "success", "âŒ Le profiling a Ã©chouÃ©"
    
    # VÃ©rifier que le profil est dans le Blackboard
    profile = bb.read("profiles", user_id)
    assert profile is not None, "âŒ Le profil n'est pas dans le Blackboard"
    
    print(f"\nğŸ“‹ Profil crÃ©Ã©:")
    print(f"  - User ID: {profile['user_id']}")
    print(f"  - Level: {profile['level']}")
    print(f"  - Style: {profile['learning_style']}")
    print(f"  - Interests: {profile['interests']}")
    
    print("\nâœ… TEST 2 RÃ‰USSI - RequÃªte 'profile_only' exÃ©cutÃ©e avec succÃ¨s")


def test_full_analysis_request():
    """Test d'une requÃªte full_analysis"""
    print("\n" + "="*80)
    print("TEST 3 : RequÃªte 'full_analysis'")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # CrÃ©er un utilisateur de test
    user_id = "test_user_002"
    setup_test_user(bb, user_id)
    
    # ExÃ©cuter une analyse complÃ¨te
    result = orchestrator.process_user_request(user_id, request_type="full_analysis")
    
    # VÃ©rifications
    assert result["overall_status"] == "completed", "âŒ L'analyse complÃ¨te a Ã©chouÃ©"
    assert len(result["agents_results"]) > 0, "âŒ Aucun agent exÃ©cutÃ©"
    
    # VÃ©rifier que tous les agents du pipeline ont Ã©tÃ© exÃ©cutÃ©s
    for agent_name in orchestrator.pipeline:
        assert agent_name in result["agents_results"], f"âŒ Agent {agent_name} non exÃ©cutÃ©"
    
    print(f"\nğŸ“Š RÃ©sultats de l'analyse complÃ¨te:")
    print(f"  - Statut global: {result['overall_status']}")
    print(f"  - Agents exÃ©cutÃ©s: {list(result['agents_results'].keys())}")
    print(f"  - DurÃ©e totale: {result.get('completed_at', 'N/A')}")
    
    print("\nâœ… TEST 3 RÃ‰USSI - Analyse complÃ¨te exÃ©cutÃ©e avec succÃ¨s")


def test_multiple_users():
    """Test avec plusieurs utilisateurs"""
    print("\n" + "="*80)
    print("TEST 4 : Traitement de plusieurs utilisateurs")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # CrÃ©er 3 utilisateurs
    users = ["user_alice", "user_bob", "user_charlie"]
    
    print(f"\nğŸ”„ Traitement de {len(users)} utilisateurs...")
    for user_id in users:
        setup_test_user(bb, user_id)
        result = orchestrator.process_user_request(user_id, request_type="profile_only")
        assert result["overall_status"] == "completed", f"âŒ Ã‰chec pour {user_id}"
    
    # VÃ©rifier que tous les profils sont crÃ©Ã©s
    all_profiles = bb.read_section("profiles")
    assert len(all_profiles) == len(users), "âŒ Tous les profils ne sont pas crÃ©Ã©s"
    
    print(f"\nğŸ“Š Profils crÃ©Ã©s:")
    for user_id in users:
        profile = bb.read("profiles", user_id)
        print(f"  - {user_id:15s} : {profile['level']:12s} | {profile['learning_style']}")
    
    # VÃ©rifier l'historique des exÃ©cutions
    history = orchestrator.get_execution_history()
    assert len(history) == len(users), "âŒ Historique incomplet"
    
    print(f"\nğŸ“œ Historique des exÃ©cutions: {len(history)} entrÃ©es")
    
    print("\nâœ… TEST 4 RÃ‰USSI - Plusieurs utilisateurs traitÃ©s avec succÃ¨s")


def test_execution_history():
    """Test de l'historique des exÃ©cutions"""
    print("\n" + "="*80)
    print("TEST 5 : Historique des exÃ©cutions")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # ExÃ©cuter plusieurs requÃªtes
    users = ["user_001", "user_002", "user_001"]  # user_001 deux fois
    
    print(f"\nğŸ”„ ExÃ©cution de {len(users)} requÃªtes...")
    for i, user_id in enumerate(users):
        setup_test_user(bb, f"{user_id}_{i}")
        orchestrator.process_user_request(f"{user_id}_{i}", request_type="profile_only")
    
    # RÃ©cupÃ©rer l'historique complet
    full_history = orchestrator.get_execution_history()
    print(f"\nğŸ“œ Historique complet: {len(full_history)} exÃ©cutions")
    
    # VÃ©rifier
    assert len(full_history) == len(users), "âŒ Historique incomplet"
    
    # Afficher les dÃ©tails
    for i, execution in enumerate(full_history, 1):
        print(f"\n  ExÃ©cution #{i}:")
        print(f"    User ID: {execution['user_id']}")
        print(f"    Type: {execution['request_type']}")
        print(f"    Statut: {execution['overall_status']}")
        print(f"    Agents: {list(execution['agents_results'].keys())}")
    
    print("\nâœ… TEST 5 RÃ‰USSI - Historique des exÃ©cutions fonctionnel")


def test_agent_status():
    """Test des statuts des agents"""
    print("\n" + "="*80)
    print("TEST 6 : Gestion des statuts d'agents")
    print("="*80)
    
    bb = Blackboard()
    orchestrator = Orchestrator(bb)
    
    # VÃ©rifier le statut initial
    initial_status = orchestrator.get_agent_status("profiling")
    print(f"\nğŸ“Š Statut initial de 'profiling': {initial_status}")
    assert initial_status == AgentStatus.PENDING, "âŒ Le statut initial devrait Ãªtre PENDING"
    
    # ExÃ©cuter une requÃªte
    user_id = "test_user_status"
    setup_test_user(bb, user_id)
    orchestrator.process_user_request(user_id, request_type="profile_only")
    
    # VÃ©rifier le statut aprÃ¨s exÃ©cution
    final_status = orchestrator.get_agent_status("profiling")
    print(f"ğŸ“Š Statut final de 'profiling': {final_status}")
    assert final_status == AgentStatus.COMPLETED, "âŒ Le statut devrait Ãªtre COMPLETED"
    
    # RÃ©initialiser les agents
    print(f"\nğŸ”„ RÃ©initialisation des agents...")
    orchestrator.reset_agents()
    
    reset_status = orchestrator.get_agent_status("profiling")
    print(f"ğŸ“Š Statut aprÃ¨s reset: {reset_status}")
    assert reset_status == AgentStatus.PENDING, "âŒ Le statut devrait Ãªtre PENDING aprÃ¨s reset"
    
    print("\nâœ… TEST 6 RÃ‰USSI - Gestion des statuts fonctionnelle")


def run_all_tests():
    """ExÃ©cuter tous les tests de l'Orchestrator"""
    print("\n" + "#"*80)
    print("# SUITE DE TESTS COMPLÃˆTE - ORCHESTRATOR")
    print("#"*80)
    
    try:
        test_orchestrator_initialization()
        test_profile_only_request()
        test_full_analysis_request()
        test_multiple_users()
        test_execution_history()
        test_agent_status()
        
        # Message final mis Ã  jour pour reflÃ©ter le systÃ¨me complet
        print("\n" + "="*80)
        print("ğŸ‰ TOUS LES TESTS DE L'ORCHESTRATOR SONT RÃ‰USSIS !")
        print("="*80)
        
        print("\nâœ… Le systÃ¨me multi-agents complet est opÃ©rationnel !")
        
        print("\nğŸ“Š Architecture implÃ©mentÃ©e (5 couches) :")
        print("  â””â”€ Layer 0 : Orchestration")
        print("     â€¢ Orchestrator (LangGraph/AutoGen)")
        print("  â””â”€ Layer 1 : Shared Memory")
        print("     â€¢ Blackboard avec Vector Database")
        print("  â””â”€ Layer 2 : Reasoning & Decision")
        print("     â€¢ Profiling Agent (Embeddings/Clustering)")
        print("     â€¢ Path Planning Agent (Graph Search/Heuristics)")
        print("     â€¢ Content Generator (LLM + RAG)")
        print("  â””â”€ Layer 3 : Explainability & Trust")
        print("     â€¢ Recommendation Agent (Hybrid Ranking)")
        print("     â€¢ XAI Agent (SHAP/LIME/Counterfactuals)")
        print("  â””â”€ Layer 4 : Data Layer")
        print("     â€¢ Ressources pÃ©dagogiques")
        print("     â€¢ Historique des interactions")
        
        print("\nğŸš€ Pipeline cognitif complet :")
        print("   User â†’ Profiling â†’ Path Planning â†’ Content Generation â†’ Recommendation â†’ XAI")
        
        print("\nğŸ’¡ Prochaines Ã©tapes suggÃ©rÃ©es :")
        print("  1. ExÃ©cuter python main.py pour voir le systÃ¨me en action")
        print("  2. Enrichir le catalogue de ressources pÃ©dagogiques")
        print("  3. Affiner les algorithmes de recommandation")
        print("  4. AmÃ©liorer les explications XAI")
        print("  5. DÃ©velopper une interface utilisateur (Web/CLI)")
        print("  6. Ajouter des mÃ©triques de performance et d'Ã©valuation")
        print("  7. ImplÃ©menter la persistance des donnÃ©es (base de donnÃ©es)")
        
        print("\n" + "="*80)
        print("ğŸŠ FÃ©licitations ! Votre systÃ¨me de recommandation explicable est prÃªt !")
        print("="*80 + "\n")
        
    except AssertionError as e:
        print(f"\nâŒ Ã‰CHEC DU TEST: {e}")
    except Exception as e:
        print(f"\nâŒ ERREUR INATTENDUE: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    run_all_tests()